{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     /Users/gregory/nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]     /Users/gregory/nltk_data...\n",
      "[nltk_data]   Package maxent_treebank_pos_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to /Users/gregory/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/gregory/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /Users/gregory/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to /Users/gregory/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import nltk import word_tokenize, pos_tag, ne_chunk\n",
    "import re\n",
    "from mordecai import Geoparser\n",
    "\n",
    "# Download NLP data for country extraction // make this modular by setting nltk data path\n",
    "nltk.download('treebank')\n",
    "nltk.download('maxent_treebank_pos_tagger')\n",
    "nltk.download('punkt') # Download corpora for GPE extraction\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "\n",
    "pd.options.display.max_rows = None  # display all rows\n",
    "pd.options.display.max_columns = None  # display all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/raw/titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "\n",
    "    # Calculate size of family including passenger\n",
    "    data['family_size'] = data['sibsp'] + data['parch'] + 1\n",
    "\n",
    "\n",
    "    # Add surname column to easily identify relatives. Neo4j can \n",
    "    # build relationships based on matching surname and family size.\n",
    "    data['surname'] = data['name'].str.split(',', expand=True)[0]\n",
    "\n",
    "    # Extract deck from cabin number\n",
    "    data['deck'] = data['cabin'].str[:1]\n",
    "    \n",
    "    # Fill incorrect NaN values of embarked with correct values for passengers\n",
    "    data.loc[data['ticket'] == '113572', 'embarked'] = 'S'\n",
    "    \n",
    "    # Replace NaN values with Unknown in destination column\n",
    "    data['home.dest'].fillna(\"Unknown Destination\", inplace=True)\n",
    "    \n",
    "    # Save\n",
    "    data.to_csv('../data/clean/titanic_clean.csv', index=False)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#data['home.dest'].str.split(' / ', expand=True)[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary of Country:[strings]\n",
    "# If row.`home.dest` is in map assign Country value\n",
    "\n",
    "countries = {\"United States\":[\"NY\", \"PA\", \"MA\", \"MN\", \"IL\", \"KS\", \"OH\", \"CA\", \"MO\", \"DC\", \"WI\", \"IA\", \n",
    "                              \"OR\", \"NJ\", \"RI\", \"MI\", \"ME\", \"CT\", \"WV\", \"ND\", \"Ohio\", \"MT\", \"UT\", \n",
    "                              \"Pennsylvania\", \"NM\", \"CO\", \"SD\", \"VT\", \"KY\", \"FL\", \"IN\", \"WA\", \"AZ\", \"NE\"], \n",
    "             \"United Kingdom\":[\"London\", \"England\", \"Middlesex\", \"Surrey\", \"Berkshire\", \"Guernsey\", \"Sussex\",\n",
    "                              \"Kent\", \"Essex\", \"Avon\", \"Wales\", \"Weston-Super-Mare\", \"Cornwall\", \"Dorset\",\n",
    "                              \"Yorks\", \"Lancashire\", \"Huntingdonshire\", \"Somerset\", \"Glasgow\", \"Devon\", \n",
    "                              \"Southington\", \"Staffs\", \"Aberdeen\", \"Liverpool\", \"Southampton\", \"Belfast\", \"Norwich\"], \n",
    "             \"France\":[\"Paris\", \"France\"], \n",
    "             \"Germany\":[\"Germany\"], \n",
    "             \"Austria\":[\"Austria\", \"Austria-Hungary\"], \n",
    "             \"Italy\":[\"Italy\"],\n",
    "             \"Greece\":[\"Greece\"], \n",
    "             \"Ireland\":[\"Ireland\", \"Co\"],\n",
    "             \"Bulgaria\":[\"Bulgaria\"], \n",
    "             \"Canada\":[\"PQ\", \"ON\", \"MB\", \"NS\", \"BC\", \"AB\", \"NB\"], \n",
    "             \"Australia\":[\"Australia\"],\n",
    "             \"Russia\":[\"Russia\", \"Moscow\"], \n",
    "             \"Cuba\":[\"Cuba\"], \n",
    "             \"Sweden\":[\"Sweden\"], \n",
    "             \"Norway\":[\"Norway\"], \n",
    "             \"Denmark\":[\"Denmark\"], \n",
    "             \"Finland\":[\"Finland\"], \n",
    "             \"Mexico\":[\"Mexico\"],\n",
    "             \"Croatia\":[\"Croatia\"], \n",
    "             \"Switzerland\":[\"Switzerland\"], \n",
    "             \"Peru\":[\"Peru\"], \n",
    "             \"Belgium\":[\"Belgium\"], \n",
    "             \"India\":[\"India\"], \n",
    "             \"South Africa\":[\"South Africa\"], \n",
    "             \"Uruguay\":[\"Uruguay\"], \n",
    "             \"Spain\":[\"Spain\"], \n",
    "             \"Japan\":[\"Japan\"], \n",
    "             \"Portugal\":[\"Portugal\"], \n",
    "             \"Syria\":[\"Syria\"], \n",
    "             \"Thailand\":[\"Thailand\"],\n",
    "             \"Argentina\":[\"Argentina\"],\n",
    "             \"Netherlands\":[\"Netherlands\"]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile('[\\W_]+')\n",
    "sentence = data['home.dest'].str.replace(pattern, ' ')[3]\n",
    "sentence2 = \"I moved from Chicago\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Montreal PQ Chesterville ON'"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'word': 'Montreal',\n",
       "  'spans': [{'start': 0, 'end': 8}],\n",
       "  'country_predicted': 'CAN',\n",
       "  'country_conf': 0.52780867},\n",
       " {'word': 'Quebec',\n",
       "  'spans': [{'start': 10, 'end': 16}],\n",
       "  'country_predicted': 'CAN',\n",
       "  'country_conf': 0.52780867},\n",
       " {'word': 'Chesterville',\n",
       "  'spans': [{'start': 18, 'end': 30}],\n",
       "  'country_predicted': 'USA',\n",
       "  'country_conf': 0.73197085,\n",
       "  'geo': {'admin1': 'South Carolina',\n",
       "   'lat': '34.70486',\n",
       "   'lon': '-81.21426',\n",
       "   'country_code3': 'USA',\n",
       "   'geonameid': '4574565',\n",
       "   'place_name': 'Chester',\n",
       "   'feature_class': 'P',\n",
       "   'feature_code': 'PPLA2'}},\n",
       " {'word': 'Ontario',\n",
       "  'spans': [{'start': 32, 'end': 39}],\n",
       "  'country_predicted': 'CAN',\n",
       "  'country_conf': 0.52780867}]"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo = Geoparser()\n",
    "geo.geoparse('Montreal, Quebec, Chesterville, Ontario')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Montreal', 'PQ', 'Chesterville', 'ON']"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list = pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = ne_chunk(pos_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (PERSON Montreal/NNP) PQ/NNP Chesterville/NNP ON/NNP)\n"
     ]
    }
   ],
   "source": [
    "print(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home[1][0] in countries['United States']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['home.dest'].str.contains('Co')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-263-81104a4abe6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcountry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcountries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcountry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcity\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dest.country'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcountries_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcountry\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "for country in countries:\n",
    "    if df.str.contains(country[city]):\n",
    "        df['dest.country'] = countries_dict[country]\n",
    "        \n",
    "        \n",
    "        #for country in countries.keys():\n",
    " #   for row in data.iterrows():\n",
    "  #      for index, destination in home.iteritems():\n",
    "   #         for idx, word in enumerate(destination):\n",
    "    #            if word in countries[country]:\n",
    "     #               #print(index)\n",
    "      #              data[row, 'country'] = countries[country]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
