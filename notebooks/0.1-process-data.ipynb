{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *RMS Titanic* dataset in Neo4j - Preprocessing\n",
    "\n",
    "This notebook is a prototype for a data processing pipeline. The two basic steps required to prepare the dataset for import into Neo4j are a cleaning step and a geoparsing step relying on Natural Language Processing (NLP).\n",
    "\n",
    "This notebook requires a running Elasticsearch container with a geonames index:\n",
    "```bash\n",
    "python -m spacy download en_core_web_lg\n",
    "docker pull elasticsearch:5.5.2\n",
    "wget https://s3.amazonaws.com/ahalterman-geo/geonames_index.tar.gz --output-file=wget_log.txt\n",
    "tar -xzf geonames_index.tar.gz\n",
    "docker run -d -p 127.0.0.1:9200:9200 -v $(pwd)/geonames_index/:/usr/share/elasticsearch/data elasticsearch:5.5.2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     /Users/gregory/nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]     /Users/gregory/nltk_data...\n",
      "[nltk_data]   Package maxent_treebank_pos_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to /Users/gregory/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/gregory/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /Users/gregory/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to /Users/gregory/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "# For NLP and geoparsing\n",
    "import nltk\n",
    "from mordecai import Geoparser\n",
    "import pycountry\n",
    "\n",
    "# Download NLP data for country extraction // make this modular by setting nltk data path\n",
    "nltk.download('treebank')\n",
    "nltk.download('maxent_treebank_pos_tagger')\n",
    "nltk.download('punkt') # Download corpora for GPE extraction\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "\n",
    "pd.options.display.max_rows = None  # display all rows\n",
    "pd.options.display.max_columns = None  # display all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path and import\n",
    "sys.path[0] = '../'\n",
    "url = 'https://query.data.world/s/xjk6hp7t7w3553bfpkfshr2bjd67a4'\n",
    "raw = sys.path[0] + 'data/raw/titanic.csv'\n",
    "data = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# String cleaning and some simple feature engineering\n",
    "def clean_data(data):\n",
    "    \n",
    "    # Calculate total size of family (same surname) including passenger\n",
    "    data['family.size'] = data['sibsp'] + data['parch'] + 1\n",
    "\n",
    "    # Add surname column to easily identify relatives. Neo4j can \n",
    "    # build relationships based on matching surname and family size.\n",
    "    data['surname'] = data['name'].str.split(',', expand=True)[0]\n",
    "    \n",
    "    # Fill NaN values for Cabins\n",
    "    #data['cabin'] = data['cabin'].fillna('Unspecified Cabin')\n",
    "\n",
    "    # Extract deck from cabin number\n",
    "    data['deck'] = data['cabin'].str[:1]\n",
    "    #data['deck'].fillna('Unspecified Deck', inplace=True)\n",
    "    \n",
    "    # Fill incorrect NaN values of embarked with correct values for passengers\n",
    "    data.loc[data['ticket'] == '113572', 'embarked'] = 'S'\n",
    "    \n",
    "    # Replace embarked with location name\n",
    "    embarked = {\"S\": \"Southampton\", \"C\": \"Cherbourg\", \"Q\": \"Queenstown\"}\n",
    "    data['embarked'] = data['embarked'].map(embarked)\n",
    "    \n",
    "    # Replace NaN values with Unknown in destination column\n",
    "    data['home.dest'].fillna(\"Unspecified Destination\", inplace=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run\n",
    "data = clean_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save. Careful not to overwrite data after lengthy ML steps.\n",
    "#data.to_csv('../data/clean/titanic_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geoparsing\n",
    "\n",
    "Geoparsing the data involves three of steps:\n",
    "1. Remapping abbreviations with full names.\n",
    "2. Extracting the country from the unstructured text in *home.dest*.\n",
    "3. Converting the parsed ISO country values into names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary of Country:[strings]\n",
    "# If row.`home.dest` is in map assign Country value\n",
    "\n",
    "abbrev_map = {\n",
    "    'Alabama': 'AL',\n",
    "    'Alaska': 'AK',\n",
    "    'American Samoa': 'AS',\n",
    "    'Arizona': 'AZ',\n",
    "    'Arkansas': 'AR',\n",
    "    'California': 'CA',\n",
    "    'Colorado': 'CO',\n",
    "    'Connecticut': 'CT',\n",
    "    'Delaware': 'DE',\n",
    "    'District of Columbia': 'DC',\n",
    "    'Florida': 'FL',\n",
    "    'Georgia': 'GA',\n",
    "    'Guam': 'GU',\n",
    "    'Hawaii': 'HI',\n",
    "    'Idaho': 'ID',\n",
    "    'Illinois': 'IL',\n",
    "    'Indiana': 'IN',\n",
    "    'Iowa': 'IA',\n",
    "    'Kansas': 'KS',\n",
    "    'Kentucky': 'KY',\n",
    "    'Louisiana': 'LA',\n",
    "    'Maine': 'ME',\n",
    "    'Maryland': 'MD',\n",
    "    'Massachusetts': 'MA',\n",
    "    'Michigan': 'MI',\n",
    "    'Minnesota': 'MN',\n",
    "    'Mississippi': 'MS',\n",
    "    'Missouri': 'MO',\n",
    "    'Montana': 'MT',\n",
    "    'Nebraska': 'NE',\n",
    "    'Nevada': 'NV',\n",
    "    'New Hampshire': 'NH',\n",
    "    'New Jersey': 'NJ',\n",
    "    'New Mexico': 'NM',\n",
    "    'New York': 'NY',\n",
    "    'North Carolina': 'NC',\n",
    "    'North Dakota': 'ND',\n",
    "    'Northern Mariana Islands':'MP',\n",
    "    'Ohio': 'OH',\n",
    "    'Oklahoma': 'OK',\n",
    "    'Oregon': 'OR',\n",
    "    'Pennsylvania': 'PA',\n",
    "    'Puerto Rico': 'PR',\n",
    "    'Rhode Island': 'RI',\n",
    "    'South Carolina': 'SC',\n",
    "    'South Dakota': 'SD',\n",
    "    'Tennessee': 'TN',\n",
    "    'Texas': 'TX',\n",
    "    'Utah': 'UT',\n",
    "    'Vermont': 'VT',\n",
    "    'Virgin Islands': 'VI',\n",
    "    'Virginia': 'VA',\n",
    "    'Washington': 'WA',\n",
    "    'West Virginia': 'WV',\n",
    "    'Wisconsin': 'WI',\n",
    "    'Wyoming': 'WY',\n",
    "    \"Alberta\": \"AB\",\n",
    "    \"British Columbia\": \"BC\",\n",
    "    \"Manitoba\": \"MB\",\n",
    "    \"New Brunswick\": \"NB\",\n",
    "    \"Newfoundland\": \"NL\",\n",
    "    \"Northwest Territories\": \"NT\",\n",
    "    \"Nova Scotia\": \"NS\",\n",
    "    \"Nunavut\": \"NU\",\n",
    "    \"Ontario\": \"ON\",\n",
    "    \"Prince Edward Island\": \"PE\",\n",
    "    \"Quebec\": \"PQ\",\n",
    "    \"Saskatchewan\": \"SK\",\n",
    "    \"Yukon\": \"YT\",\n",
    "    \"Northern Ireland\": \"NI\"}\n",
    "\n",
    "# Invert mappings\n",
    "abbrev_map = {v: k for k, v in abbrev_map.items()}\n",
    "\n",
    "# Apply mappings to replace state abbreviations\n",
    "#data['home.dest'] = data['home.dest'].str.split().apply(lambda x: ' '.join([abbrev_map.get(word, word) for word in x]))\n",
    "\n",
    "# Refactor as function\n",
    "def remap_abbrev(series):\n",
    "    remapper = lambda row: ' '.join([abbrev_map.get(word, word) for word in row])\n",
    "    series = series.str.split().apply(remapper)\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "data['home.dest'] = remap_abbrev(data['home.dest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "      <th>family.size</th>\n",
       "      <th>surname</th>\n",
       "      <th>deck</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, Missouri</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Allen</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, Quebec / Chesterville, Ontario</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Allison</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, Quebec / Chesterville, Ontario</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Allison</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Montreal, Quebec / Chesterville, Ontario</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Allison</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, Quebec / Chesterville, Ontario</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Allison</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived                                             name     sex  \\\n",
       "0     1.0       1.0                    Allen, Miss. Elisabeth Walton  female   \n",
       "1     1.0       1.0                   Allison, Master. Hudson Trevor    male   \n",
       "2     1.0       0.0                     Allison, Miss. Helen Loraine  female   \n",
       "3     1.0       0.0             Allison, Mr. Hudson Joshua Creighton    male   \n",
       "4     1.0       0.0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n",
       "\n",
       "       age  sibsp  parch  ticket      fare    cabin     embarked boat   body  \\\n",
       "0  29.0000    0.0    0.0   24160  211.3375       B5  Southampton    2    NaN   \n",
       "1   0.9167    1.0    2.0  113781  151.5500  C22 C26  Southampton   11    NaN   \n",
       "2   2.0000    1.0    2.0  113781  151.5500  C22 C26  Southampton  NaN    NaN   \n",
       "3  30.0000    1.0    2.0  113781  151.5500  C22 C26  Southampton  NaN  135.0   \n",
       "4  25.0000    1.0    2.0  113781  151.5500  C22 C26  Southampton  NaN    NaN   \n",
       "\n",
       "                                  home.dest  family.size  surname deck  \n",
       "0                        St Louis, Missouri          1.0    Allen    B  \n",
       "1  Montreal, Quebec / Chesterville, Ontario          4.0  Allison    C  \n",
       "2  Montreal, Quebec / Chesterville, Ontario          4.0  Allison    C  \n",
       "3  Montreal, Quebec / Chesterville, Ontario          4.0  Allison    C  \n",
       "4  Montreal, Quebec / Chesterville, Ontario          4.0  Allison    C  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can be used with Pandas apply method. Use batch version for better speed.\n",
    "def extract_country(row):\n",
    "    geo = Geoparser(country_threshold=0.9)\n",
    "    inferred = geo.geoparse(row)\n",
    "    country_range = range(len(inferred))\n",
    "    home_countries = set([inferred[i]['country_predicted'] for i in country_range])\n",
    "    home_countries = \", \".join(home_countries)\n",
    "    \n",
    "    return home_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_geoparse uses nlp.pipe to speed things up\n",
    "def batch_extract_country(series):\n",
    "    countries = []\n",
    "    geo = Geoparser()\n",
    "    batch = geo.batch_geoparse(series)\n",
    "    for doc_list in batch:\n",
    "        row = \", \".join(set([entry['country_predicted'] for entry in doc_list]))\n",
    "        countries.append(row)\n",
    "    \n",
    "    return pd.Series(countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts country ISO abbreviation to English name\n",
    "def lookup_country_name(row):\n",
    "    if row == \"\":\n",
    "        return \"\"\n",
    "    else:\n",
    "        words = row.split(', ')\n",
    "        lookup = lambda country: pycountry.countries.lookup(country).name\n",
    "        names = list(map(lookup, words))\n",
    "        names = \", \".join(names)\n",
    "        return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  3.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# Reduce size (optional, takes less time)\n",
    "data = data[:5]\n",
    "\n",
    "# Geoparses home.dest to infer destination countries for each passenger. Outputs ISO abbreviation.\n",
    "# This step takes a while depending on the machine.\n",
    "data['home.country'] = batch_extract_country(data['home.dest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "      <th>family.size</th>\n",
       "      <th>surname</th>\n",
       "      <th>deck</th>\n",
       "      <th>home.country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, Missouri</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Allen</td>\n",
       "      <td>B</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, Quebec / Chesterville, Ontario</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Allison</td>\n",
       "      <td>C</td>\n",
       "      <td>CAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, Quebec / Chesterville, Ontario</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Allison</td>\n",
       "      <td>C</td>\n",
       "      <td>CAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Montreal, Quebec / Chesterville, Ontario</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Allison</td>\n",
       "      <td>C</td>\n",
       "      <td>CAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, Quebec / Chesterville, Ontario</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Allison</td>\n",
       "      <td>C</td>\n",
       "      <td>CAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived                                             name     sex  \\\n",
       "0     1.0       1.0                    Allen, Miss. Elisabeth Walton  female   \n",
       "1     1.0       1.0                   Allison, Master. Hudson Trevor    male   \n",
       "2     1.0       0.0                     Allison, Miss. Helen Loraine  female   \n",
       "3     1.0       0.0             Allison, Mr. Hudson Joshua Creighton    male   \n",
       "4     1.0       0.0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n",
       "\n",
       "       age  sibsp  parch  ticket      fare    cabin     embarked boat   body  \\\n",
       "0  29.0000    0.0    0.0   24160  211.3375       B5  Southampton    2    NaN   \n",
       "1   0.9167    1.0    2.0  113781  151.5500  C22 C26  Southampton   11    NaN   \n",
       "2   2.0000    1.0    2.0  113781  151.5500  C22 C26  Southampton  NaN    NaN   \n",
       "3  30.0000    1.0    2.0  113781  151.5500  C22 C26  Southampton  NaN  135.0   \n",
       "4  25.0000    1.0    2.0  113781  151.5500  C22 C26  Southampton  NaN    NaN   \n",
       "\n",
       "                                  home.dest  family.size  surname deck  \\\n",
       "0                        St Louis, Missouri          1.0    Allen    B   \n",
       "1  Montreal, Quebec / Chesterville, Ontario          4.0  Allison    C   \n",
       "2  Montreal, Quebec / Chesterville, Ontario          4.0  Allison    C   \n",
       "3  Montreal, Quebec / Chesterville, Ontario          4.0  Allison    C   \n",
       "4  Montreal, Quebec / Chesterville, Ontario          4.0  Allison    C   \n",
       "\n",
       "  home.country  \n",
       "0          USA  \n",
       "1          CAN  \n",
       "2          CAN  \n",
       "3          CAN  \n",
       "4          CAN  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts ISO country code to country name. Having the country name makes a better label for the node.\n",
    "data['home.country'] = data['home.country'].apply(lookup_country_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "      <th>family.size</th>\n",
       "      <th>surname</th>\n",
       "      <th>deck</th>\n",
       "      <th>home.country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, Missouri</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Allen</td>\n",
       "      <td>B</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, Quebec / Chesterville, Ontario</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Allison</td>\n",
       "      <td>C</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, Quebec / Chesterville, Ontario</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Allison</td>\n",
       "      <td>C</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Montreal, Quebec / Chesterville, Ontario</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Allison</td>\n",
       "      <td>C</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, Quebec / Chesterville, Ontario</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Allison</td>\n",
       "      <td>C</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived                                             name     sex  \\\n",
       "0     1.0       1.0                    Allen, Miss. Elisabeth Walton  female   \n",
       "1     1.0       1.0                   Allison, Master. Hudson Trevor    male   \n",
       "2     1.0       0.0                     Allison, Miss. Helen Loraine  female   \n",
       "3     1.0       0.0             Allison, Mr. Hudson Joshua Creighton    male   \n",
       "4     1.0       0.0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n",
       "\n",
       "       age  sibsp  parch  ticket      fare    cabin     embarked boat   body  \\\n",
       "0  29.0000    0.0    0.0   24160  211.3375       B5  Southampton    2    NaN   \n",
       "1   0.9167    1.0    2.0  113781  151.5500  C22 C26  Southampton   11    NaN   \n",
       "2   2.0000    1.0    2.0  113781  151.5500  C22 C26  Southampton  NaN    NaN   \n",
       "3  30.0000    1.0    2.0  113781  151.5500  C22 C26  Southampton  NaN  135.0   \n",
       "4  25.0000    1.0    2.0  113781  151.5500  C22 C26  Southampton  NaN    NaN   \n",
       "\n",
       "                                  home.dest  family.size  surname deck  \\\n",
       "0                        St Louis, Missouri          1.0    Allen    B   \n",
       "1  Montreal, Quebec / Chesterville, Ontario          4.0  Allison    C   \n",
       "2  Montreal, Quebec / Chesterville, Ontario          4.0  Allison    C   \n",
       "3  Montreal, Quebec / Chesterville, Ontario          4.0  Allison    C   \n",
       "4  Montreal, Quebec / Chesterville, Ontario          4.0  Allison    C   \n",
       "\n",
       "    home.country  \n",
       "0  United States  \n",
       "1         Canada  \n",
       "2         Canada  \n",
       "3         Canada  \n",
       "4         Canada  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final dataset\n",
    "#data.to_csv(sys.path[0] + 'data/clean/titanic_final.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
